{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22133846",
   "metadata": {},
   "source": [
    "# VectorBTåŒèµ„äº§å†å¹³è¡¡ç­–ç•¥æ·±åº¦æ¢ç´¢\n",
    "\n",
    "æœ¬ç¬”è®°æœ¬å°†`ImprovedVectorBTStrategy`æ‹†åˆ†æˆç‹¬ç«‹çš„å‡½æ•°ï¼Œè®©æ‚¨å¯ä»¥åˆ†æ­¥éª¤åœ°ç†è§£æ¯ä¸ªç»„ä»¶çš„å†…éƒ¨åŠŸèƒ½å’Œç»“æ„ã€‚\n",
    "\n",
    "## ç­–ç•¥æ¦‚è¿°\n",
    "\n",
    "è¿™æ˜¯ä¸€ä¸ªåŸºäºHolt-Wintersé¢„æµ‹å’Œç£æ»å›çº¿é€»è¾‘çš„åŒèµ„äº§å†å¹³è¡¡ç­–ç•¥ï¼š\n",
    "\n",
    "1. **Holt-Wintersä¿¡å·è®¡ç®—** - ä½¿ç”¨HWDPæ¨¡å‹ç”Ÿæˆè¶‹åŠ¿é¢„æµ‹ä¿¡å·\n",
    "2. **ç£æ»å›çº¿é€»è¾‘** - é€šè¿‡é˜ˆå€¼åˆ¤æ–­é¿å…é¢‘ç¹äº¤æ˜“\n",
    "3. **åŠ¨æ€æƒé‡åˆ†é…** - æ ¹æ®ä¿¡å·åœ¨ä¸åŒæƒé‡é…ç½®é—´åˆ‡æ¢\n",
    "4. **æ™ºèƒ½å†å¹³è¡¡** - ä»…åœ¨æƒé‡å˜åŒ–ä¸”åˆ°è¾¾å†å¹³è¡¡æ—¥æœŸæ—¶æ‰§è¡Œäº¤æ˜“\n",
    "5. **VectorBTæ¡†æ¶** - ä½¿ç”¨ä¸“ä¸šå›æµ‹æ¡†æ¶è¿›è¡Œæ€§èƒ½åˆ†æ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19019586",
   "metadata": {},
   "source": [
    "## 1. å¯¼å…¥åº“å’Œç¯å¢ƒè®¾ç½®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee78e3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯¼å…¥æ‰€éœ€åº“\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import vectorbt as vbt\n",
    "import matplotlib.pyplot as plt\n",
    "from dffc.holt_winters._holt_winters import HWDP\n",
    "from dffc.holt_winters._optimization import process_hw_opt\n",
    "from dffc.fund_data import register_fund_data\n",
    "\n",
    "# è®¾ç½®vectorbté…ç½®\n",
    "print(\"é…ç½®vectorbtè®¾ç½®...\")\n",
    "vbt.settings.array_wrapper['freq'] = 'days'          # æ—¶é—´é¢‘ç‡ä¸ºå¤©\n",
    "vbt.settings.returns['year_freq'] = '252 days'       # å¹´åŒ–å¤©æ•°ï¼ˆäº¤æ˜“æ—¥ï¼‰\n",
    "vbt.settings.portfolio['seed'] = 42                  # éšæœºç§å­ç¡®ä¿å¯é‡å¤æ€§\n",
    "vbt.settings.portfolio.stats['incl_unrealized'] = True  # åŒ…å«æœªå®ç°ç›ˆäº\n",
    "\n",
    "# è®¾ç½®ä¸­æ–‡å­—ä½“æ”¯æŒ\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "print(\"ç¯å¢ƒè®¾ç½®å®Œæˆï¼\")\n",
    "print(f\"VectorBTç‰ˆæœ¬: {vbt.__version__}\")\n",
    "print(\"VectorBTè®¾ç½®å·²é…ç½®ä¸º:\")\n",
    "print(f\"- é¢‘ç‡: {vbt.settings.array_wrapper['freq']}\")\n",
    "print(f\"- å¹´åŒ–é¢‘ç‡: {vbt.settings.returns['year_freq']}\")\n",
    "print(f\"- éšæœºç§å­: {vbt.settings.portfolio['seed']}\")\n",
    "print(f\"- åŒ…å«æœªå®ç°ç›ˆäº: {vbt.settings.portfolio.stats['incl_unrealized']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1ad875",
   "metadata": {},
   "source": [
    "## 2. æ•°æ®åŠ è½½å’Œå‡†å¤‡å‡½æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfee1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_fund_data(fund_codes, fund_names, start_date, end_date):\n",
    "    \"\"\"\n",
    "    åŠ è½½åŸºé‡‘æ•°æ®\n",
    "    \n",
    "    Args:\n",
    "        fund_codes: list, åŸºé‡‘ä»£ç åˆ—è¡¨\n",
    "        fund_names: list, åŸºé‡‘åç§°åˆ—è¡¨  \n",
    "        start_date: str, å¼€å§‹æ—¥æœŸ\n",
    "        end_date: str, ç»“æŸæ—¥æœŸ\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: ä»·æ ¼æ•°æ®\n",
    "    \"\"\"\n",
    "    print(\"æ³¨å†ŒåŸºé‡‘æ•°æ®æº...\")\n",
    "    register_fund_data()\n",
    "    \n",
    "    print(f\"ä¸‹è½½åŸºé‡‘æ•°æ®: {fund_codes}\")\n",
    "    print(f\"æ—¥æœŸèŒƒå›´: {start_date} è‡³ {end_date}\")\n",
    "    \n",
    "    fund_data = vbt.FundData.download(\n",
    "        fund_codes,\n",
    "        names=fund_names,\n",
    "        start=start_date,\n",
    "        end=end_date\n",
    "    )\n",
    "    \n",
    "    prices = fund_data.get('cumulative_value').dropna()\n",
    "    \n",
    "    print(f\"æ•°æ®åŠ è½½å®Œæˆï¼\")\n",
    "    print(f\"æ•°æ®å½¢çŠ¶: {prices.shape}\")\n",
    "    print(f\"æ•°æ®åˆ—: {list(prices.columns)}\")\n",
    "    print(f\"æ—¥æœŸèŒƒå›´: {prices.index[0]} è‡³ {prices.index[-1]}\")\n",
    "    \n",
    "    return prices\n",
    "\n",
    "# åŠ è½½å®é™…æ•°æ®\n",
    "prices = load_fund_data(\n",
    "    fund_codes=['007467', '004253'],\n",
    "    fund_names=['HL', 'GD'], \n",
    "    start_date='2022-07-01',\n",
    "    end_date='2025-07-01'\n",
    ")\n",
    "\n",
    "# æ˜¾ç¤ºæ•°æ®é¢„è§ˆ\n",
    "print(\"\\nå‰5è¡Œæ•°æ®:\")\n",
    "print(prices.head())\n",
    "print(\"\\nå5è¡Œæ•°æ®:\")\n",
    "print(prices.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5348b957",
   "metadata": {},
   "source": [
    "## 3. Holt-Wintersä¿¡å·è®¡ç®—å‡½æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44faa431",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_hw_signals(prices, optimization=True):\n",
    "    \"\"\"\n",
    "    è®¡ç®—Holt-Wintersä¿¡å·\n",
    "    \n",
    "    Args:\n",
    "        prices: DataFrame, ä»·æ ¼æ•°æ®\n",
    "        optimization: bool, æ˜¯å¦ä¼˜åŒ–HWå‚æ•°\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: HWä¿¡å·æ•°æ®\n",
    "    \"\"\"\n",
    "    print(\"å¼€å§‹è®¡ç®—Holt-Wintersä¿¡å·...\")\n",
    "    \n",
    "    hw_signals = pd.DataFrame(index=prices.index, columns=prices.columns)\n",
    "    \n",
    "    if optimization:\n",
    "        print(\"æ­£åœ¨ä¼˜åŒ–Holt-Winterså‚æ•°...\")\n",
    "        # ä½¿ç”¨ä¼˜åŒ–ç®—æ³•å¯»æ‰¾æœ€ä½³å‚æ•°\n",
    "        result = process_hw_opt(prices, \".\", 8)\n",
    "        hw_params = {}\n",
    "        \n",
    "        for fund_result in result:\n",
    "            hw_params[fund_result['fundcode']] = {\n",
    "                'alpha': fund_result['alpha'],\n",
    "                'beta': fund_result['beta'], \n",
    "                'gamma': fund_result['gamma'],\n",
    "                'm': fund_result['season']\n",
    "            }\n",
    "            print(f\"åŸºé‡‘ {fund_result['fundcode']} ä¼˜åŒ–å‚æ•°:\")\n",
    "            print(f\"  alpha={fund_result['alpha']:.3f}, beta={fund_result['beta']:.3f}\")\n",
    "            print(f\"  gamma={fund_result['gamma']:.3f}, m={fund_result['season']}\")\n",
    "    else:\n",
    "        print(\"ä½¿ç”¨é»˜è®¤å‚æ•°...\")\n",
    "        # ä½¿ç”¨é»˜è®¤å‚æ•°\n",
    "        hw_params = {col: {'alpha': 0.3, 'beta': 0.1, 'gamma': 0.1, 'm': 8} \n",
    "                    for col in prices.columns}\n",
    "        \n",
    "    # ä¸ºæ¯ä¸ªèµ„äº§è®¡ç®—HWä¿¡å·\n",
    "    for col in prices.columns:\n",
    "        params = hw_params[col]\n",
    "        print(f\"è®¡ç®— {col} çš„HWDPä¿¡å·...\")\n",
    "        \n",
    "        hwdp_result = HWDP.run(\n",
    "            prices[col], \n",
    "            alpha=params['alpha'],\n",
    "            beta=params['beta'], \n",
    "            gamma=params['gamma'],\n",
    "            m=params['m'],\n",
    "            multiplicative=True\n",
    "        )\n",
    "        hw_signals[col] = hwdp_result.hwdp\n",
    "        \n",
    "    print(\"Holt-Wintersä¿¡å·è®¡ç®—å®Œæˆï¼\")\n",
    "    return hw_signals\n",
    "\n",
    "# è®¡ç®—HWä¿¡å·\n",
    "hw_signals = calculate_hw_signals(prices, optimization=True)\n",
    "\n",
    "# æ˜¾ç¤ºä¿¡å·ç»Ÿè®¡\n",
    "print(\"\\nHWä¿¡å·ç»Ÿè®¡:\")\n",
    "print(hw_signals.describe())\n",
    "\n",
    "# è®¡ç®—ä¿¡å·å·®å€¼\n",
    "delta_hdp = hw_signals.iloc[:, 0] - hw_signals.iloc[:, 1]\n",
    "print(f\"\\nHDPå·®å€¼ç»Ÿè®¡:\")\n",
    "print(f\"å‡å€¼: {delta_hdp.mean():.4f}\")\n",
    "print(f\"æ ‡å‡†å·®: {delta_hdp.std():.4f}\")\n",
    "print(f\"æœ€å¤§å€¼: {delta_hdp.max():.4f}\")\n",
    "print(f\"æœ€å°å€¼: {delta_hdp.min():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bedec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_hdp.to_csv(\"./d_hwdp.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c92303c",
   "metadata": {},
   "source": [
    "## 4. ç£æ»å›çº¿é€»è¾‘å’Œç›®æ ‡æƒé‡ç”Ÿæˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a511c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_target_weights(hw_signals, prices, \n",
    "                           default_weights=[0.5, 0.5],\n",
    "                           up_weights=[0.2, 0.8], \n",
    "                           down_weights=[0.8, 0.2],\n",
    "                           threshold=0.6):\n",
    "    \"\"\"\n",
    "    ä½¿ç”¨ç£æ»å›çº¿é€»è¾‘ç”Ÿæˆç›®æ ‡æƒé‡åºåˆ—\n",
    "    \n",
    "    Args:\n",
    "        hw_signals: DataFrame, HWä¿¡å·æ•°æ®\n",
    "        prices: DataFrame, ä»·æ ¼æ•°æ®ï¼ˆç”¨äºè·å–ç´¢å¼•å’Œåˆ—åï¼‰\n",
    "        default_weights: list, é»˜è®¤æƒé‡ [èµ„äº§1, èµ„äº§2]\n",
    "        up_weights: list, ä¸Šå‡è¶‹åŠ¿æƒé‡ [èµ„äº§1, èµ„äº§2]  \n",
    "        down_weights: list, ä¸‹é™è¶‹åŠ¿æƒé‡ [èµ„äº§1, èµ„äº§2]\n",
    "        threshold: float, ç£æ»å›çº¿é˜ˆå€¼\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: ç›®æ ‡æƒé‡åºåˆ—\n",
    "        pd.Series: äº¤æ˜“ä¿¡å·åºåˆ—\n",
    "    \"\"\"\n",
    "    print(\"ç”Ÿæˆç›®æ ‡æƒé‡åºåˆ—...\")\n",
    "    print(f\"æƒé‡é…ç½®:\")\n",
    "    print(f\"  é»˜è®¤æƒé‡: {default_weights}\")\n",
    "    print(f\"  ä¸Šå‡æƒé‡: {up_weights}\")  \n",
    "    print(f\"  ä¸‹é™æƒé‡: {down_weights}\")\n",
    "    print(f\"  é˜ˆå€¼: {threshold}\")\n",
    "    \n",
    "    # è®¡ç®—HDPå·®å€¼ (ç¬¬ä¸€ä¸ªèµ„äº§ - ç¬¬äºŒä¸ªèµ„äº§)\n",
    "    delta_hdp = hw_signals.iloc[:, 0] - hw_signals.iloc[:, 1]\n",
    "    \n",
    "    # åˆå§‹åŒ–ä¿¡å·åºåˆ—\n",
    "    signals = pd.Series(index=prices.index, dtype=int)\n",
    "    signals.iloc[0] = 0  # åˆå§‹ä¿¡å·ä¸ºä¸­æ€§\n",
    "    \n",
    "    # ç£æ»å›çº¿çŠ¶æ€è®°å¿†\n",
    "    memory_switch = True  # Trueè¡¨ç¤ºå¯ä»¥å‘ä¸Šåˆ‡æ¢ï¼ŒFalseè¡¨ç¤ºå¯ä»¥å‘ä¸‹åˆ‡æ¢\n",
    "    signal_changes = []  # è®°å½•ä¿¡å·å˜åŒ–\n",
    "    \n",
    "    print(\"æ‰§è¡Œç£æ»å›çº¿é€»è¾‘...\")\n",
    "    \n",
    "    for i in range(1, len(delta_hdp)):\n",
    "        prev_switch = memory_switch\n",
    "        \n",
    "        if prev_switch and delta_hdp.iloc[i] > threshold:\n",
    "            # å¯ä»¥å‘ä¸Šåˆ‡æ¢ä¸”ä¿¡å·è¶…è¿‡ä¸Šé˜ˆå€¼\n",
    "            signals.iloc[i] = 1  # ä¸Šå‡ä¿¡å·\n",
    "            memory_switch = False  # ç°åœ¨åªèƒ½å‘ä¸‹åˆ‡æ¢\n",
    "            if signals.iloc[i-1] != 1:\n",
    "                signal_changes.append((delta_hdp.index[i], 'ä¸Šå‡ä¿¡å·', delta_hdp.iloc[i]))\n",
    "                \n",
    "        elif not prev_switch and delta_hdp.iloc[i] < -threshold:\n",
    "            # å¯ä»¥å‘ä¸‹åˆ‡æ¢ä¸”ä¿¡å·ä½äºä¸‹é˜ˆå€¼\n",
    "            signals.iloc[i] = -1  # ä¸‹é™ä¿¡å·\n",
    "            memory_switch = True   # ç°åœ¨åªèƒ½å‘ä¸Šåˆ‡æ¢\n",
    "            if signals.iloc[i-1] != -1:\n",
    "                signal_changes.append((delta_hdp.index[i], 'ä¸‹é™ä¿¡å·', delta_hdp.iloc[i]))\n",
    "                \n",
    "        else:\n",
    "            # ä¿æŒå‰ä¸€ä¸ªä¿¡å·\n",
    "            signals.iloc[i] = signals.iloc[i-1]\n",
    "    \n",
    "    print(f\"ä¿¡å·å˜åŒ–æ¬¡æ•°: {len(signal_changes)}\")\n",
    "    for date, signal_type, value in signal_changes[:5]:  # æ˜¾ç¤ºå‰5æ¬¡å˜åŒ–\n",
    "        print(f\"  {date.date()}: {signal_type}, HDPå·®å€¼={value:.4f}\")\n",
    "    \n",
    "    # æ ¹æ®ä¿¡å·ç”Ÿæˆç›®æ ‡æƒé‡\n",
    "    target_weights = pd.DataFrame(index=prices.index, columns=prices.columns)\n",
    "    \n",
    "    for i in range(len(signals)):\n",
    "        if signals.iloc[i] == 1:\n",
    "            target_weights.iloc[i] = up_weights    # ä¸Šå‡è¶‹åŠ¿æƒé‡\n",
    "        elif signals.iloc[i] == -1:\n",
    "            target_weights.iloc[i] = down_weights  # ä¸‹é™è¶‹åŠ¿æƒé‡\n",
    "        else:\n",
    "            if i == 0:\n",
    "                target_weights.iloc[i] = default_weights  # åˆå§‹é»˜è®¤æƒé‡\n",
    "            else:\n",
    "                target_weights.iloc[i] = target_weights.iloc[i-1]  # ä¿æŒå‰ä¸€æƒé‡\n",
    "    \n",
    "    # ç»Ÿè®¡æƒé‡åˆ†å¸ƒ\n",
    "    weight_stats = {}\n",
    "    for weight_type, weights in [('é»˜è®¤', default_weights), ('ä¸Šå‡', up_weights), ('ä¸‹é™', down_weights)]:\n",
    "        count = 0\n",
    "        for i in range(len(target_weights)):\n",
    "            if np.allclose(target_weights.iloc[i].values, weights):\n",
    "                count += 1\n",
    "        weight_stats[weight_type] = count\n",
    "    \n",
    "    print(\"\\\\næƒé‡åˆ†å¸ƒç»Ÿè®¡:\")\n",
    "    for weight_type, count in weight_stats.items():\n",
    "        percentage = count / len(target_weights) * 100\n",
    "        print(f\"  {weight_type}æƒé‡: {count}å¤© ({percentage:.1f}%)\")\n",
    "    \n",
    "    return target_weights, signals\n",
    "\n",
    "# ç”Ÿæˆç›®æ ‡æƒé‡\n",
    "target_weights, signals = generate_target_weights(\n",
    "    hw_signals, prices,\n",
    "    default_weights=[0.5, 0.5],\n",
    "    up_weights=[0.2, 0.8],\n",
    "    down_weights=[0.8, 0.2], \n",
    "    threshold=0.6\n",
    ")\n",
    "\n",
    "print(\"\\\\nç›®æ ‡æƒé‡ç¤ºä¾‹:\")\n",
    "print(target_weights.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e0e077",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_weights.to_csv(\"./temp.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a268751d",
   "metadata": {},
   "source": [
    "## 5. å†å¹³è¡¡æ—¶é—´è¡¨åˆ›å»º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b0a40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rebalance_schedule(prices, rebalance_freq='M'):\n",
    "    \"\"\"\n",
    "    åˆ›å»ºå†å¹³è¡¡æ—¶é—´è¡¨\n",
    "    \n",
    "    Args:\n",
    "        prices: DataFrame, ä»·æ ¼æ•°æ®\n",
    "        rebalance_freq: str, å†å¹³è¡¡é¢‘ç‡ ('D', 'W', 'M', 'Q')\n",
    "        \n",
    "    Returns:\n",
    "        pd.Series: å†å¹³è¡¡æ©ç ï¼ˆTrueè¡¨ç¤ºè¯¥æ—¥æœŸå¯ä»¥å†å¹³è¡¡ï¼‰\n",
    "    \"\"\"\n",
    "    print(f\"åˆ›å»ºå†å¹³è¡¡æ—¶é—´è¡¨ï¼Œé¢‘ç‡: {rebalance_freq}\")\n",
    "    \n",
    "    if rebalance_freq == 'D':\n",
    "        # æ¯æ—¥å†å¹³è¡¡\n",
    "        rb_mask = pd.Series(True, index=prices.index)\n",
    "        desc = \"æ¯æ—¥\"\n",
    "    elif rebalance_freq == 'W':\n",
    "        # æ¯å‘¨å†å¹³è¡¡ï¼ˆå‘¨æœŸå¼€å§‹æ—¥ï¼‰  \n",
    "        rb_mask = ~prices.index.to_period('W').duplicated()\n",
    "        desc = \"æ¯å‘¨\"\n",
    "    elif rebalance_freq == 'M':\n",
    "        # æ¯æœˆå†å¹³è¡¡ï¼ˆæœˆåˆï¼‰\n",
    "        rb_mask = ~prices.index.to_period('M').duplicated()\n",
    "        desc = \"æ¯æœˆ\"\n",
    "    elif rebalance_freq == 'Q':\n",
    "        # æ¯å­£åº¦å†å¹³è¡¡ï¼ˆå­£åº¦å¼€å§‹ï¼‰\n",
    "        rb_mask = ~prices.index.to_period('Q').duplicated()\n",
    "        desc = \"æ¯å­£åº¦\"\n",
    "    else:\n",
    "        raise ValueError(\"rebalance_freq must be one of 'D', 'W', 'M', 'Q'\")\n",
    "    \n",
    "    rb_count = rb_mask.sum()\n",
    "    print(f\"{desc}å†å¹³è¡¡ï¼Œå…± {rb_count} ä¸ªå†å¹³è¡¡æœºä¼š\")\n",
    "    \n",
    "    # æ˜¾ç¤ºå‰å‡ ä¸ªå†å¹³è¡¡æ—¥æœŸ\n",
    "    rb_dates = prices.index[rb_mask]\n",
    "    print(f\"å‰10ä¸ªå†å¹³è¡¡æ—¥æœŸ: {rb_dates[:10].date.tolist()}\")\n",
    "    \n",
    "    return rb_mask\n",
    "\n",
    "def create_actual_rebalance_mask(target_weights, rebalance_schedule):\n",
    "    \"\"\"\n",
    "    åˆ›å»ºå®é™…å†å¹³è¡¡æ©ç ï¼ˆç»“åˆæƒé‡å˜åŒ–å’Œå†å¹³è¡¡æ—¶æœºï¼‰\n",
    "    \n",
    "    Args:\n",
    "        target_weights: DataFrame, ç›®æ ‡æƒé‡\n",
    "        rebalance_schedule: pd.Series, å†å¹³è¡¡æ—¶é—´è¡¨\n",
    "        \n",
    "    Returns:\n",
    "        pd.Series: å®é™…å†å¹³è¡¡æ©ç \n",
    "    \"\"\"\n",
    "    print(\"åˆ›å»ºå®é™…å†å¹³è¡¡æ©ç ...\")\n",
    "    \n",
    "    actual_rebalances = pd.Series(False, index=target_weights.index)\n",
    "    \n",
    "    # ç¬¬ä¸€å¤©ä¸€å®šè¦åˆå§‹åŒ–\n",
    "    actual_rebalances.iloc[0] = True\n",
    "    current_target = target_weights.iloc[0].copy()\n",
    "    \n",
    "    rebalance_count = 0\n",
    "    \n",
    "    for i in range(1, len(target_weights)):\n",
    "        if rebalance_schedule.iloc[i]:\n",
    "            # è¿™æ˜¯ä¸€ä¸ªå†å¹³è¡¡æœºä¼šæ—¥\n",
    "            new_target = target_weights.iloc[i]\n",
    "            if not new_target.equals(current_target):\n",
    "                # ç›®æ ‡æƒé‡å‘ç”Ÿäº†å˜åŒ–ï¼Œéœ€è¦å†å¹³è¡¡\n",
    "                actual_rebalances.iloc[i] = True\n",
    "                current_target = new_target.copy()\n",
    "                rebalance_count += 1\n",
    "    \n",
    "    print(f\"å®é™…å†å¹³è¡¡æ¬¡æ•°: {actual_rebalances.sum()}\")\n",
    "    print(f\"æƒé‡å˜åŒ–è§¦å‘çš„å†å¹³è¡¡: {rebalance_count}\")\n",
    "    \n",
    "    # æ˜¾ç¤ºå®é™…å†å¹³è¡¡æ—¥æœŸ\n",
    "    actual_rb_dates = target_weights.index[actual_rebalances]\n",
    "    print(f\"å‰10ä¸ªå®é™…å†å¹³è¡¡æ—¥æœŸ: {actual_rb_dates[:10].date.tolist()}\")\n",
    "    \n",
    "    return actual_rebalances\n",
    "\n",
    "# æµ‹è¯•ä¸åŒå†å¹³è¡¡é¢‘ç‡\n",
    "for freq, desc in [('D', 'æ¯æ—¥'), ('W', 'æ¯å‘¨'), ('M', 'æ¯æœˆ'), ('Q', 'æ¯å­£åº¦')]:\n",
    "    print(f\"\\\\n=== {desc}å†å¹³è¡¡æµ‹è¯• ===\")\n",
    "    rebalance_schedule = create_rebalance_schedule(prices, freq)\n",
    "    actual_rebalances = create_actual_rebalance_mask(target_weights, rebalance_schedule)\n",
    "\n",
    "# ä½¿ç”¨æœˆåº¦å†å¹³è¡¡ä½œä¸ºæœ€ç»ˆé€‰æ‹©\n",
    "print(\"\\\\n=== é€‰æ‹©æœˆåº¦å†å¹³è¡¡ä½œä¸ºæœ€ç»ˆç­–ç•¥ ===\")\n",
    "final_rebalance_schedule = create_rebalance_schedule(prices, 'M')\n",
    "final_actual_rebalances = create_actual_rebalance_mask(target_weights, final_rebalance_schedule)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87825ffc",
   "metadata": {},
   "source": [
    "## 6. å›æµ‹æ•°æ®ç»“æ„å‡†å¤‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f380bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_backtest_data(prices, target_weights, rebalance_mask, adjust_factor=0.2):\n",
    "    \"\"\"\n",
    "    å‡†å¤‡vectorbtå›æµ‹æ‰€éœ€çš„æ•°æ®ç»“æ„\n",
    "    \n",
    "    Args:\n",
    "        prices: DataFrame, ä»·æ ¼æ•°æ®\n",
    "        target_weights: DataFrame, ç›®æ ‡æƒé‡\n",
    "        rebalance_mask: pd.Series, å†å¹³è¡¡æ©ç \n",
    "        adjust_factor: float, æƒé‡è°ƒæ•´å› å­ï¼ˆæ¸è¿›è°ƒæ•´ï¼‰\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (MultiIndexä»·æ ¼æ•°æ®, è®¢å•çŸ©é˜µ)\n",
    "    \"\"\"\n",
    "    print(\"å‡†å¤‡å›æµ‹æ•°æ®ç»“æ„...\")\n",
    "    \n",
    "    # 1. åˆ›å»ºMultiIndexç»“æ„ï¼ˆvectorbtè¦æ±‚ï¼‰\n",
    "    num_tests = 1\n",
    "    _prices = prices.vbt.tile(num_tests, keys=pd.Index(np.arange(num_tests), name='symbol_group'))\n",
    "    print(f\"ä»·æ ¼æ•°æ®ç»“æ„: {_prices.shape}\")\n",
    "    print(f\"MultiIndexåˆ—: {_prices.columns}\")\n",
    "    \n",
    "    # 2. åˆ›å»ºè®¢å•çŸ©é˜µ\n",
    "    orders = np.full_like(_prices, np.nan)  # åˆå§‹åŒ–ä¸ºNaNï¼ˆæ— è®¢å•ï¼‰\n",
    "    \n",
    "    # 3. ç¬¬ä¸€å¤©åˆå§‹åŒ–\n",
    "    orders[0, :] = target_weights.iloc[0].values\n",
    "    print(f\"åˆå§‹æƒé‡: {target_weights.iloc[0].values}\")\n",
    "    \n",
    "    # 4. åœ¨å†å¹³è¡¡æ—¥æœŸè®¾ç½®ç›®æ ‡æƒé‡ï¼ˆåº”ç”¨è°ƒæ•´å› å­ï¼‰\n",
    "    rebalance_count = 0\n",
    "    \n",
    "    for i, should_rebalance in enumerate(rebalance_mask):\n",
    "        if should_rebalance and i > 0:\n",
    "            current_target = target_weights.iloc[i].values\n",
    "            prev_target = target_weights.iloc[i-1].values\n",
    "            \n",
    "            # åº”ç”¨è°ƒæ•´å› å­è¿›è¡Œæ¸è¿›è°ƒæ•´\n",
    "            weight_diff = current_target - prev_target\n",
    "            adjusted_target = prev_target + weight_diff * adjust_factor\n",
    "            \n",
    "            orders[i, :] = adjusted_target\n",
    "            rebalance_count += 1\n",
    "            \n",
    "            if rebalance_count <= 5:  # æ˜¾ç¤ºå‰5æ¬¡å†å¹³è¡¡\n",
    "                print(f\"å†å¹³è¡¡ {rebalance_count}: {prices.index[i].date()}\")\n",
    "                print(f\"  å‰æƒé‡: {prev_target}\")\n",
    "                print(f\"  ç›®æ ‡æƒé‡: {current_target}\")\n",
    "                print(f\"  è°ƒæ•´åæƒé‡: {adjusted_target}\")\n",
    "    \n",
    "    print(f\"\\\\næ€»å†å¹³è¡¡æ¬¡æ•°: {rebalance_count}\")\n",
    "    \n",
    "    # 5. ç»Ÿè®¡è®¢å•çŸ©é˜µ\n",
    "    non_nan_orders = ~np.isnan(orders).all(axis=1)\n",
    "    print(f\"æœ‰æ•ˆè®¢å•æ—¥æœŸæ•°: {non_nan_orders.sum()}\")\n",
    "    \n",
    "    return _prices, orders\n",
    "\n",
    "def show_order_analysis(orders, prices, rebalance_mask):\n",
    "    \"\"\"\n",
    "    åˆ†æè®¢å•çŸ©é˜µ\n",
    "    \n",
    "    Args:\n",
    "        orders: numpy.array, è®¢å•çŸ©é˜µ\n",
    "        prices: DataFrame, ä»·æ ¼æ•°æ®\n",
    "        rebalance_mask: pd.Series, å†å¹³è¡¡æ©ç \n",
    "    \"\"\"\n",
    "    print(\"\\\\n=== è®¢å•åˆ†æ ===\")\n",
    "    \n",
    "    # æ‰¾åˆ°æ‰€æœ‰æœ‰è®¢å•çš„æ—¥æœŸ\n",
    "    has_orders = ~np.isnan(orders).all(axis=1)\n",
    "    order_dates = prices.index[has_orders]\n",
    "    \n",
    "    print(f\"æ€»è®¢å•å¤©æ•°: {len(order_dates)}\")\n",
    "    print(f\"è®¢å•å æ¯”: {len(order_dates)/len(prices)*100:.2f}%\")\n",
    "    \n",
    "    # æŒ‰æœˆç»Ÿè®¡è®¢å•\n",
    "    order_months = pd.to_datetime(order_dates).to_period('M').value_counts().sort_index()\n",
    "    print(f\"\\\\næŒ‰æœˆè®¢å•åˆ†å¸ƒ:\")\n",
    "    for month, count in order_months.head().items():\n",
    "        print(f\"  {month}: {count}ä¸ªè®¢å•\")\n",
    "    \n",
    "    # æ£€æŸ¥è®¢å•å’Œå†å¹³è¡¡çš„å¯¹åº”å…³ç³»\n",
    "    rebalance_dates = prices.index[rebalance_mask]\n",
    "    orders_match_rebalance = set(order_dates) == set(rebalance_dates)\n",
    "    print(f\"\\\\nè®¢å•æ—¥æœŸä¸å†å¹³è¡¡æ—¥æœŸåŒ¹é…: {orders_match_rebalance}\")\n",
    "    \n",
    "    return order_dates\n",
    "\n",
    "# å‡†å¤‡å›æµ‹æ•°æ®\n",
    "_prices, orders = prepare_backtest_data(prices, target_weights, final_actual_rebalances, adjust_factor=0.2)\n",
    "\n",
    "# åˆ†æè®¢å•\n",
    "order_dates = show_order_analysis(orders, prices, final_actual_rebalances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dee421e",
   "metadata": {},
   "source": [
    "## 7. æ‰§è¡ŒVectorBTç»„åˆå›æµ‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9526d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_vectorbt_backtest(_prices, orders, initial_cash=100000, fees=0.001):\n",
    "    \"\"\"\n",
    "    ä½¿ç”¨VectorBTæ‰§è¡Œç»„åˆå›æµ‹\n",
    "    \n",
    "    Args:\n",
    "        _prices: DataFrame, MultiIndexä»·æ ¼æ•°æ®\n",
    "        orders: numpy.array, è®¢å•çŸ©é˜µ\n",
    "        initial_cash: float, åˆå§‹èµ„é‡‘\n",
    "        fees: float, äº¤æ˜“è´¹ç‡\n",
    "        \n",
    "    Returns:\n",
    "        vbt.Portfolio: å›æµ‹ç»“æœç»„åˆå¯¹è±¡\n",
    "    \"\"\"\n",
    "    print(\"=== å¼€å§‹VectorBTå›æµ‹ ===\")\n",
    "    print(f\"åˆå§‹èµ„é‡‘: {initial_cash:,}\")\n",
    "    print(f\"äº¤æ˜“è´¹ç‡: {fees*100:.2f}%\")\n",
    "    print(f\"è®¢å•ç±»å‹: TargetPercent (ç›®æ ‡ç™¾åˆ†æ¯”)\")\n",
    "    \n",
    "    # ä½¿ç”¨vectorbtæ‰§è¡Œå›æµ‹\n",
    "    portfolio = vbt.Portfolio.from_orders(\n",
    "        close=_prices,                    # ä»·æ ¼æ•°æ®\n",
    "        size=orders,                      # è®¢å•å¤§å°ï¼ˆæƒé‡ï¼‰\n",
    "        size_type='TargetPercent',        # è®¢å•ç±»å‹ï¼šç›®æ ‡ç™¾åˆ†æ¯”\n",
    "        group_by='symbol_group',          # æŒ‰ç»„åˆ†ç»„\n",
    "        cash_sharing=True,                # ç»„å†…å…±äº«ç°é‡‘\n",
    "        call_seq='auto',                  # è°ƒç”¨åºåˆ—ï¼šè‡ªåŠ¨ï¼ˆå…ˆå–åä¹°ï¼‰\n",
    "        fees=fees,                        # äº¤æ˜“è´¹ç”¨\n",
    "        init_cash=initial_cash,           # åˆå§‹ç°é‡‘\n",
    "        freq='1D',                        # é¢‘ç‡ï¼šæ—¥\n",
    "        min_size=1,                       # æœ€å°è®¢å•å¤§å°\n",
    "        size_granularity=1                # è®¢å•ç²’åº¦\n",
    "    )\n",
    "    \n",
    "    print(\"å›æµ‹å®Œæˆï¼\")\n",
    "    print(f\"å›æµ‹æœŸé—´: {portfolio.wrapper.index[0].date()} è‡³ {portfolio.wrapper.index[-1].date()}\")\n",
    "    print(f\"å›æµ‹å¤©æ•°: {len(portfolio.wrapper.index)}\")\n",
    "    \n",
    "    return portfolio\n",
    "\n",
    "# æ‰§è¡Œå›æµ‹\n",
    "portfolio = run_vectorbt_backtest(_prices, orders, initial_cash=100000, fees=0.001)\n",
    "\n",
    "# å¿«é€ŸæŸ¥çœ‹åŸºæœ¬ä¿¡æ¯\n",
    "print(\"\\\\n=== åŸºæœ¬å›æµ‹ä¿¡æ¯ ===\")\n",
    "print(f\"æœ€ç»ˆç»„åˆä»·å€¼: {portfolio.value().iloc[-1]:,.2f}\")\n",
    "print(f\"æ€»æ”¶ç›Š: {portfolio.total_return()*100:.2f}%\")\n",
    "print(f\"å¹´åŒ–æ”¶ç›Š: {portfolio.annualized_return()*100:.2f}%\")\n",
    "print(f\"å¤æ™®æ¯”ç‡: {portfolio.sharpe_ratio():.2f}\")\n",
    "print(f\"æœ€å¤§å›æ’¤: {portfolio.max_drawdown()*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d248c7",
   "metadata": {},
   "source": [
    "## 8. ç­–ç•¥è¡¨ç°æ·±åº¦åˆ†æ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd1254b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_strategy_performance(portfolio, prices):\n",
    "    \"\"\"\n",
    "    æ·±åº¦åˆ†æç­–ç•¥è¡¨ç°\n",
    "    \n",
    "    Args:\n",
    "        portfolio: vbt.Portfolio, ç»„åˆå¯¹è±¡\n",
    "        prices: DataFrame, åŸå§‹ä»·æ ¼æ•°æ®\n",
    "        \n",
    "    Returns:\n",
    "        dict: åˆ†æç»“æœå­—å…¸\n",
    "    \"\"\"\n",
    "    print(\"=== ç­–ç•¥è¡¨ç°æ·±åº¦åˆ†æ ===\")\n",
    "    \n",
    "    # 1. æ•´ä½“ç»Ÿè®¡æ•°æ®\n",
    "    stats = portfolio.stats()\n",
    "    print(\"\\\\n1. æ•´ä½“ç»Ÿè®¡:\")\n",
    "    print(stats)\n",
    "    \n",
    "    # 2. é£é™©æ”¶ç›ŠæŒ‡æ ‡\n",
    "    print(\"\\\\n2. å…³é”®é£é™©æ”¶ç›ŠæŒ‡æ ‡:\")\n",
    "    total_return = portfolio.total_return() * 100\n",
    "    annual_return = portfolio.annualized_return() * 100\n",
    "    volatility = portfolio.annualized_volatility() * 100\n",
    "    sharpe = portfolio.sharpe_ratio()\n",
    "    max_dd = portfolio.max_drawdown() * 100\n",
    "    calmar = portfolio.calmar_ratio()\n",
    "    \n",
    "    metrics = {\n",
    "        'æ€»æ”¶ç›Šç‡': f\"{total_return:.2f}%\",\n",
    "        'å¹´åŒ–æ”¶ç›Šç‡': f\"{annual_return:.2f}%\", \n",
    "        'å¹´åŒ–æ³¢åŠ¨ç‡': f\"{volatility:.2f}%\",\n",
    "        'å¤æ™®æ¯”ç‡': f\"{sharpe:.2f}\",\n",
    "        'æœ€å¤§å›æ’¤': f\"{max_dd:.2f}%\",\n",
    "        'å¡ç›æ¯”ç‡': f\"{calmar:.2f}\"\n",
    "    }\n",
    "    \n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"  {metric}: {value}\")\n",
    "    \n",
    "    # 3. ä¸ªè‚¡è¡¨ç°åˆ†æ\n",
    "    print(\"\\\\n3. ä¸ªè‚¡è¡¨ç°:\")\n",
    "    try:\n",
    "        individual_returns = portfolio.total_return(group_by=False) * 100\n",
    "        for i, (asset, ret) in enumerate(individual_returns.items()):\n",
    "            print(f\"  {prices.columns[i]}: {ret:.2f}%\")\n",
    "    except:\n",
    "        print(\"  æ— æ³•è·å–ä¸ªè‚¡è¡¨ç°æ•°æ®\")\n",
    "    \n",
    "    # 4. äº¤æ˜“åˆ†æ\n",
    "    print(\"\\\\n4. äº¤æ˜“åˆ†æ:\")\n",
    "    try:\n",
    "        orders_count = portfolio.orders.count()\n",
    "        total_trades = orders_count.sum() if hasattr(orders_count, 'sum') else orders_count\n",
    "        \n",
    "        fees_paid = portfolio.orders.fees.sum()\n",
    "        total_fees = fees_paid.sum() if hasattr(fees_paid, 'sum') else fees_paid\n",
    "        \n",
    "        print(f\"  æ€»äº¤æ˜“æ¬¡æ•°: {total_trades}\")\n",
    "        print(f\"  æ€»äº¤æ˜“è´¹ç”¨: {total_fees:.2f}\")\n",
    "        print(f\"  å¹³å‡æ¯ç¬”è´¹ç”¨: {total_fees/max(1, total_trades):.2f}\")\n",
    "        \n",
    "        # è´¹ç”¨å æ”¶ç›Šæ¯”ä¾‹\n",
    "        portfolio_value = portfolio.value()\n",
    "        total_profit = portfolio_value.iloc[-1] - portfolio_value.iloc[0]\n",
    "        fee_ratio = total_fees / total_profit * 100 if total_profit > 0 else 0\n",
    "        print(f\"  è´¹ç”¨å åˆ©æ¶¦æ¯”ä¾‹: {fee_ratio:.2f}%\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  äº¤æ˜“åˆ†æé”™è¯¯: {e}\")\n",
    "    \n",
    "    # 5. æ—¶é—´åºåˆ—åˆ†æ\n",
    "    print(\"\\\\n5. æ—¶é—´åºåˆ—åˆ†æ:\")\n",
    "    portfolio_value = portfolio.value()\n",
    "    returns = portfolio_value.pct_change().dropna()\n",
    "    \n",
    "    print(f\"  æ—¥å‡æ”¶ç›Šç‡: {returns.mean()*100:.4f}%\")\n",
    "    print(f\"  æ”¶ç›Šç‡æ ‡å‡†å·®: {returns.std()*100:.4f}%\") \n",
    "    print(f\"  æ­£æ”¶ç›Šå¤©æ•°: {(returns > 0).sum()}\")\n",
    "    print(f\"  è´Ÿæ”¶ç›Šå¤©æ•°: {(returns < 0).sum()}\")\n",
    "    print(f\"  èƒœç‡: {(returns > 0).mean()*100:.1f}%\")\n",
    "    \n",
    "    # 6. ä¸åŸºå‡†æ¯”è¾ƒ\n",
    "    print(\"\\\\n6. ä¸ç­‰æƒé‡åŸºå‡†æ¯”è¾ƒ:\")\n",
    "    benchmark_returns = prices.pct_change().mean(axis=1).fillna(0)\n",
    "    benchmark_cumret = (1 + benchmark_returns).cumprod()\n",
    "    benchmark_total_return = (benchmark_cumret.iloc[-1] - 1) * 100\n",
    "    \n",
    "    print(f\"  åŸºå‡†æ€»æ”¶ç›Š: {benchmark_total_return:.2f}%\")\n",
    "    print(f\"  è¶…é¢æ”¶ç›Š: {total_return - benchmark_total_return:.2f}%\")\n",
    "    print(f\"  ä¿¡æ¯æ¯”ç‡: {(annual_return - benchmark_total_return*252/len(benchmark_returns))/volatility:.2f}\")\n",
    "    \n",
    "    return {\n",
    "        'total_return': total_return,\n",
    "        'annual_return': annual_return,\n",
    "        'volatility': volatility,\n",
    "        'sharpe_ratio': sharpe,\n",
    "        'max_drawdown': max_dd,\n",
    "        'benchmark_return': benchmark_total_return,\n",
    "        'excess_return': total_return - benchmark_total_return\n",
    "    }\n",
    "\n",
    "# æ‰§è¡Œæ·±åº¦åˆ†æ\n",
    "analysis_results = analyze_strategy_performance(portfolio, prices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7fa141",
   "metadata": {},
   "source": [
    "## 9. å¯è§†åŒ–åˆ†æå’Œå›¾è¡¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1c451c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_comprehensive_plots(prices, hw_signals, target_weights, portfolio, rebalance_mask, signals):\n",
    "    \"\"\"\n",
    "    åˆ›å»ºç»¼åˆå¯è§†åŒ–å›¾è¡¨\n",
    "    \n",
    "    Args:\n",
    "        prices: DataFrame, ä»·æ ¼æ•°æ®\n",
    "        hw_signals: DataFrame, HWä¿¡å·\n",
    "        target_weights: DataFrame, ç›®æ ‡æƒé‡\n",
    "        portfolio: vbt.Portfolio, ç»„åˆå¯¹è±¡\n",
    "        rebalance_mask: pd.Series, å†å¹³è¡¡æ©ç \n",
    "        signals: pd.Series, äº¤æ˜“ä¿¡å·\n",
    "    \"\"\"\n",
    "    # åˆ›å»ºå­å›¾\n",
    "    fig, axes = plt.subplots(5, 1, figsize=(16, 20))\n",
    "    \n",
    "    # 1. èµ„äº§ä»·æ ¼èµ°åŠ¿\n",
    "    axes[0].plot(prices.index, prices.iloc[:, 0], label=prices.columns[0], linewidth=2, color='blue')\n",
    "    axes[0].plot(prices.index, prices.iloc[:, 1], label=prices.columns[1], linewidth=2, color='orange')\n",
    "    axes[0].set_title('èµ„äº§ä»·æ ¼èµ°åŠ¿', fontsize=14, fontweight='bold')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    axes[0].set_ylabel('ç´¯è®¡å‡€å€¼')\n",
    "    \n",
    "    # 2. HWä¿¡å·å’Œé˜ˆå€¼\n",
    "    delta_hdp = hw_signals.iloc[:, 0] - hw_signals.iloc[:, 1]\n",
    "    axes[1].plot(delta_hdp.index, delta_hdp, label='HDPå·®å€¼', linewidth=2, color='green')\n",
    "    axes[1].axhline(y=0.6, color='r', linestyle='--', label='ä¸Šé˜ˆå€¼ (0.6)', alpha=0.8)\n",
    "    axes[1].axhline(y=-0.6, color='r', linestyle='--', label='ä¸‹é˜ˆå€¼ (-0.6)', alpha=0.8)\n",
    "    axes[1].axhline(y=0, color='k', linestyle='-', alpha=0.3)\n",
    "    \n",
    "    # æ ‡è®°ä¿¡å·å˜åŒ–ç‚¹\n",
    "    signal_changes = signals.diff() != 0\n",
    "    signal_change_dates = signals.index[signal_changes]\n",
    "    for date in signal_change_dates:\n",
    "        axes[1].axvline(x=date, color='purple', linestyle=':', alpha=0.6)\n",
    "    \n",
    "    axes[1].set_title('Holt-Wintersä¿¡å·å·®å€¼ä¸äº¤æ˜“ä¿¡å·', fontsize=14, fontweight='bold')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    axes[1].set_ylabel('HDPå·®å€¼')\n",
    "    \n",
    "    # 3. ç›®æ ‡æƒé‡å˜åŒ–\n",
    "    axes[2].plot(target_weights.index, target_weights.iloc[:, 0], \n",
    "                 label=f'{prices.columns[0]}æƒé‡', linewidth=2, color='blue')\n",
    "    axes[2].plot(target_weights.index, target_weights.iloc[:, 1], \n",
    "                 label=f'{prices.columns[1]}æƒé‡', linewidth=2, color='orange')\n",
    "    \n",
    "    # æ ‡è®°å†å¹³è¡¡æ—¥æœŸ\n",
    "    rb_dates = target_weights.index[rebalance_mask]\n",
    "    for i, rb_date in enumerate(rb_dates):\n",
    "        if i < 5:  # åªæ ‡è®°å‰å‡ ä¸ªï¼Œé¿å…å›¾è¡¨è¿‡ä¹±\n",
    "            axes[2].axvline(x=rb_date, color='gray', linestyle=':', alpha=0.7)\n",
    "    \n",
    "    axes[2].set_title('ç›®æ ‡æƒé‡åˆ†é…å˜åŒ–', fontsize=14, fontweight='bold')\n",
    "    axes[2].set_ylim(0, 1)\n",
    "    axes[2].legend()\n",
    "    axes[2].grid(True, alpha=0.3)\n",
    "    axes[2].set_ylabel('æƒé‡')\n",
    "    \n",
    "    # 4. å®é™…æƒé‡åˆ†é…ï¼ˆå †å é¢ç§¯å›¾ï¼‰\n",
    "    try:\n",
    "        asset_values = portfolio.asset_value(group_by=False)\n",
    "        total_value = portfolio.value()\n",
    "        actual_weights = asset_values.div(total_value, axis=0)\n",
    "        \n",
    "        axes[3].fill_between(actual_weights.index, 0, actual_weights.iloc[:, 0], \n",
    "                            label=prices.columns[0], alpha=0.7, color='blue')\n",
    "        axes[3].fill_between(actual_weights.index, actual_weights.iloc[:, 0], 1,\n",
    "                            label=prices.columns[1], alpha=0.7, color='orange')\n",
    "        \n",
    "        axes[3].set_title('å®é™…æƒé‡åˆ†é…å˜åŒ–', fontsize=14, fontweight='bold')\n",
    "        axes[3].set_ylim(0, 1)\n",
    "        axes[3].legend()\n",
    "        axes[3].grid(True, alpha=0.3)\n",
    "        axes[3].set_ylabel('å®é™…æƒé‡')\n",
    "    except:\n",
    "        axes[3].text(0.5, 0.5, 'æ— æ³•æ˜¾ç¤ºå®é™…æƒé‡æ•°æ®', ha='center', va='center', transform=axes[3].transAxes)\n",
    "        axes[3].set_title('å®é™…æƒé‡åˆ†é…å˜åŒ–ï¼ˆæ•°æ®ä¸å¯ç”¨ï¼‰', fontsize=14)\n",
    "    \n",
    "    # 5. ç´¯è®¡æ”¶ç›Šå¯¹æ¯”\n",
    "    portfolio_value = portfolio.value()\n",
    "    portfolio_returns = portfolio_value / portfolio_value.iloc[0]\n",
    "    \n",
    "    # è®¡ç®—ç­‰æƒé‡åŸºå‡†\n",
    "    benchmark_returns = prices.pct_change().mean(axis=1).fillna(0)\n",
    "    benchmark_cumret = (1 + benchmark_returns).cumprod()\n",
    "    \n",
    "    # è®¡ç®—ä¸ªè‚¡è¡¨ç°\n",
    "    asset1_return = prices.iloc[:, 0] / prices.iloc[0, 0]\n",
    "    asset2_return = prices.iloc[:, 1] / prices.iloc[0, 1]\n",
    "    \n",
    "    axes[4].plot(portfolio_returns.index, portfolio_returns, \n",
    "                 label='å†å¹³è¡¡ç­–ç•¥', linewidth=3, color='red')\n",
    "    axes[4].plot(benchmark_cumret.index, benchmark_cumret, \n",
    "                 label='ç­‰æƒé‡åŸºå‡†', linewidth=2, color='gray')\n",
    "    axes[4].plot(asset1_return.index, asset1_return, \n",
    "                 label=prices.columns[0], linewidth=1, alpha=0.7, color='blue')\n",
    "    axes[4].plot(asset2_return.index, asset2_return, \n",
    "                 label=prices.columns[1], linewidth=1, alpha=0.7, color='orange')\n",
    "    \n",
    "    axes[4].set_title('ç´¯è®¡æ”¶ç›Šå¯¹æ¯”', fontsize=14, fontweight='bold')\n",
    "    axes[4].legend()\n",
    "    axes[4].grid(True, alpha=0.3)\n",
    "    axes[4].set_ylabel('ç´¯è®¡æ”¶ç›Š')\n",
    "    axes[4].set_xlabel('æ—¥æœŸ')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # æ‰“å°æœ€ç»ˆæ”¶ç›Šå¯¹æ¯”\n",
    "    print(\"\\\\n=== æ”¶ç›Šå¯¹æ¯”æ€»ç»“ ===\")\n",
    "    strategy_return = (portfolio_returns.iloc[-1] - 1) * 100\n",
    "    benchmark_return = (benchmark_cumret.iloc[-1] - 1) * 100\n",
    "    asset1_ret = (asset1_return.iloc[-1] - 1) * 100\n",
    "    asset2_ret = (asset2_return.iloc[-1] - 1) * 100\n",
    "    \n",
    "    print(f\"å†å¹³è¡¡ç­–ç•¥: {strategy_return:.2f}%\")\n",
    "    print(f\"ç­‰æƒé‡åŸºå‡†: {benchmark_return:.2f}%\") \n",
    "    print(f\"{prices.columns[0]}å•ç‹¬æŒæœ‰: {asset1_ret:.2f}%\")\n",
    "    print(f\"{prices.columns[1]}å•ç‹¬æŒæœ‰: {asset2_ret:.2f}%\")\n",
    "    print(f\"ç­–ç•¥è¶…é¢æ”¶ç›Š: {strategy_return - benchmark_return:.2f}%\")\n",
    "\n",
    "# åˆ›å»ºç»¼åˆå¯è§†åŒ–\n",
    "create_comprehensive_plots(prices, hw_signals, target_weights, portfolio, final_actual_rebalances, signals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59255e5c",
   "metadata": {},
   "source": [
    "## 10. ç­–ç•¥æ€»ç»“å’Œå…³é”®æ´å¯Ÿ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a730ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_strategy_insights(analysis_results):\n",
    "    \"\"\"\n",
    "    æ€»ç»“ç­–ç•¥å…³é”®æ´å¯Ÿ\n",
    "    \n",
    "    Args:\n",
    "        analysis_results: dict, åˆ†æç»“æœ\n",
    "    \"\"\"\n",
    "    print(\"=== ğŸ¯ VectorBTåŒèµ„äº§å†å¹³è¡¡ç­–ç•¥æ€»ç»“ ===\")\n",
    "    print()\n",
    "    \n",
    "    # 1. ç­–ç•¥æ ¸å¿ƒæœºåˆ¶\n",
    "    print(\"ğŸ“‹ **ç­–ç•¥æ ¸å¿ƒæœºåˆ¶:**\")\n",
    "    print(\"  1ï¸âƒ£ Holt-Wintersæ¨¡å‹é¢„æµ‹è¶‹åŠ¿ â†’ ç”ŸæˆHWDPä¿¡å·\")\n",
    "    print(\"  2ï¸âƒ£ ç£æ»å›çº¿é€»è¾‘ â†’ é¿å…é¢‘ç¹äº¤æ˜“å™ªéŸ³\") \n",
    "    print(\"  3ï¸âƒ£ åŠ¨æ€æƒé‡åˆ†é… â†’ [0.2,0.8] â†” [0.8,0.2]\")\n",
    "    print(\"  4ï¸âƒ£ æ™ºèƒ½å†å¹³è¡¡ â†’ ä»…åœ¨æƒé‡å˜åŒ–æ—¶æ‰§è¡Œ\")\n",
    "    print(\"  5ï¸âƒ£ VectorBTæ¡†æ¶ â†’ ä¸“ä¸šå›æµ‹å’Œåˆ†æ\")\n",
    "    print()\n",
    "    \n",
    "    # 2. å…³é”®å‚æ•°è®¾ç½®\n",
    "    print(\"âš™ï¸ **å…³é”®å‚æ•°è®¾ç½®:**\")\n",
    "    print(\"  â€¢ ç£æ»é˜ˆå€¼: Â±0.6 (é¿å…é¢‘ç¹åˆ‡æ¢)\")\n",
    "    print(\"  â€¢ æƒé‡é…ç½®: ä¸Šå‡[0.2,0.8] vs ä¸‹é™[0.8,0.2]\")\n",
    "    print(\"  â€¢ è°ƒæ•´å› å­: 0.2 (æ¸è¿›å¼æƒé‡è°ƒæ•´)\")\n",
    "    print(\"  â€¢ å†å¹³è¡¡é¢‘ç‡: æœˆåº¦ (å¹³è¡¡æˆæœ¬ä¸æ•ˆæœ)\")\n",
    "    print(\"  â€¢ äº¤æ˜“è´¹ç”¨: 0.1% (ç°å®äº¤æ˜“æˆæœ¬)\")\n",
    "    print()\n",
    "    \n",
    "    # 3. ç­–ç•¥è¡¨ç°äº®ç‚¹\n",
    "    print(\"ğŸ† **ç­–ç•¥è¡¨ç°äº®ç‚¹:**\")\n",
    "    print(f\"  ğŸ“ˆ æ€»æ”¶ç›Šç‡: {analysis_results['total_return']:.2f}%\")\n",
    "    print(f\"  ğŸ“Š å¹´åŒ–æ”¶ç›Š: {analysis_results['annual_return']:.2f}%\")\n",
    "    print(f\"  âš¡ å¤æ™®æ¯”ç‡: {analysis_results['sharpe_ratio']:.2f}\")\n",
    "    print(f\"  ğŸ›¡ï¸ æœ€å¤§å›æ’¤: {analysis_results['max_drawdown']:.2f}%\")\n",
    "    print(f\"  ğŸ¯ è¶…é¢æ”¶ç›Š: {analysis_results['excess_return']:.2f}%\")\n",
    "    print()\n",
    "    \n",
    "    # 4. ç­–ç•¥ä¼˜åŠ¿\n",
    "    print(\"âœ… **ç­–ç•¥ä¼˜åŠ¿:**\")\n",
    "    advantages = [\n",
    "        \"è‡ªé€‚åº”æƒé‡åˆ†é… - æ ¹æ®å¸‚åœºè¶‹åŠ¿åŠ¨æ€è°ƒæ•´\",\n",
    "        \"ç£æ»æœºåˆ¶é˜²å™ª - å‡å°‘è™šå‡ä¿¡å·é€ æˆçš„è¿‡åº¦äº¤æ˜“\", \n",
    "        \"ä¸“ä¸šå›æµ‹æ¡†æ¶ - VectorBTç¡®ä¿ç»“æœå¯é æ€§\",\n",
    "        \"æˆæœ¬æ§åˆ¶è‰¯å¥½ - æœˆåº¦å†å¹³è¡¡å¹³è¡¡æ”¶ç›Šä¸è´¹ç”¨\",\n",
    "        \"é£é™©ç®¡ç†æœ‰æ•ˆ - åˆ†æ•£æŠ•èµ„é™ä½å•ä¸€èµ„äº§é£é™©\"\n",
    "    ]\n",
    "    for i, advantage in enumerate(advantages, 1):\n",
    "        print(f\"  {i}. {advantage}\")\n",
    "    print()\n",
    "    \n",
    "    # 5. æ½œåœ¨æ”¹è¿›æ–¹å‘\n",
    "    print(\"ğŸ”§ **æ½œåœ¨æ”¹è¿›æ–¹å‘:**\")\n",
    "    improvements = [\n",
    "        \"å‚æ•°ä¼˜åŒ– - ä½¿ç”¨é—ä¼ ç®—æ³•æˆ–è´å¶æ–¯ä¼˜åŒ–å¯»æ‰¾æœ€ä¼˜å‚æ•°ç»„åˆ\",\n",
    "        \"å¤šèµ„äº§æ‰©å±• - æ”¯æŒ3ä¸ªä»¥ä¸Šèµ„äº§çš„ç»„åˆé…ç½®\",\n",
    "        \"é£é™©é¢„ç®— - åŸºäºæ³¢åŠ¨ç‡çš„åŠ¨æ€æƒé‡åˆ†é…\",\n",
    "        \"å¸‚åœºçŠ¶æ€è¯†åˆ« - ç»“åˆVIXç­‰æŒ‡æ ‡åˆ¤æ–­å¸‚åœºç¯å¢ƒ\", \n",
    "        \"æœºå™¨å­¦ä¹ å¢å¼º - ä½¿ç”¨æ·±åº¦å­¦ä¹ æ”¹è¿›ä¿¡å·é¢„æµ‹\"\n",
    "    ]\n",
    "    for i, improvement in enumerate(improvements, 1):\n",
    "        print(f\"  {i}. {improvement}\")\n",
    "    print()\n",
    "    \n",
    "    # 6. ä½¿ç”¨å»ºè®®\n",
    "    print(\"ğŸ’¡ **ä½¿ç”¨å»ºè®®:**\")\n",
    "    suggestions = [\n",
    "        \"é€‚åˆä¸­é•¿æœŸæŠ•èµ„ - ç­–ç•¥åŸºäºè¶‹åŠ¿é¢„æµ‹ï¼ŒçŸ­æœŸå¯èƒ½æœ‰æ»å\",\n",
    "        \"å®šæœŸå‚æ•°æ ¡å‡† - å¸‚åœºç¯å¢ƒå˜åŒ–æ—¶é‡æ–°ä¼˜åŒ–å‚æ•°\",\n",
    "        \"é£é™©ç›‘æ§ - è®¾ç½®æ­¢æŸæœºåˆ¶é˜²èŒƒæç«¯å¸‚åœºæƒ…å†µ\",\n",
    "        \"èµ„é‡‘è§„æ¨¡è€ƒè™‘ - å¤§èµ„é‡‘éœ€è€ƒè™‘æµåŠ¨æ€§å’Œå†²å‡»æˆæœ¬\",\n",
    "        \"ç¨åŠ¡è§„åˆ’ - åˆç†å®‰æ’äº¤æ˜“æ—¶æœºä¼˜åŒ–ç¨åæ”¶ç›Š\"\n",
    "    ]\n",
    "    for i, suggestion in enumerate(suggestions, 1):\n",
    "        print(f\"  {i}. {suggestion}\")\n",
    "    print()\n",
    "    \n",
    "    print(\"ğŸ‰ **æ­å–œï¼æ‚¨å·²æˆåŠŸæŒæ¡VectorBTåŒèµ„äº§å†å¹³è¡¡ç­–ç•¥çš„æ ¸å¿ƒæŠ€æœ¯ï¼**\")\n",
    "    print(\"ğŸ’» å¯ä»¥åœ¨æ­¤åŸºç¡€ä¸Šç»§ç»­æ¢ç´¢æ›´å¤šé‡åŒ–æŠ•èµ„ç­–ç•¥ã€‚\")\n",
    "\n",
    "# ç”Ÿæˆç­–ç•¥æ€»ç»“\n",
    "summarize_strategy_insights(analysis_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b53f79",
   "metadata": {},
   "source": [
    "## ğŸ” æ¢ç´¢å®Œæˆï¼\n",
    "\n",
    "æ‚¨ç°åœ¨å·²ç»å®Œå…¨ç†è§£äº†`ImprovedVectorBTStrategy`çš„å†…éƒ¨å·¥ä½œæœºåˆ¶ï¼š\n",
    "\n",
    "### ğŸ“š å­¦ä¹ æ”¶è·\n",
    "\n",
    "1. **æ¨¡å—åŒ–è®¾è®¡** - æ¯ä¸ªåŠŸèƒ½è¢«æ‹†åˆ†ä¸ºç‹¬ç«‹å‡½æ•°ï¼Œä¾¿äºç†è§£å’Œä¿®æ”¹\n",
    "2. **VectorBTæ¡†æ¶** - æŒæ¡äº†ä¸“ä¸šé‡åŒ–å›æµ‹å·¥å…·çš„ä½¿ç”¨æ–¹æ³•  \n",
    "3. **ä¿¡å·ç”Ÿæˆ** - ç†è§£Holt-Wintersæ¨¡å‹åœ¨é‡åŒ–ç­–ç•¥ä¸­çš„åº”ç”¨\n",
    "4. **é£é™©æ§åˆ¶** - å­¦ä¼šä½¿ç”¨ç£æ»å›çº¿é¿å…è¿‡åº¦äº¤æ˜“\n",
    "5. **æ€§èƒ½è¯„ä¼°** - å…¨é¢çš„å›æµ‹åˆ†æå’Œå¯è§†åŒ–æŠ€å·§\n",
    "\n",
    "### ğŸš€ ä¸‹ä¸€æ­¥å»ºè®®\n",
    "\n",
    "- å°è¯•ä¿®æ”¹å‚æ•°ï¼Œè§‚å¯Ÿå¯¹ç­–ç•¥è¡¨ç°çš„å½±å“\n",
    "- æ‰©å±•åˆ°æ›´å¤šèµ„äº§çš„ç»„åˆç®¡ç†\n",
    "- æ¢ç´¢å…¶ä»–æŠ€æœ¯æŒ‡æ ‡ä¸Holt-Wintersçš„ç»“åˆ\n",
    "- ç ”ç©¶ä¸åŒå¸‚åœºç¯å¢ƒä¸‹çš„ç­–ç•¥é€‚åº”æ€§\n",
    "\n",
    "### ğŸ’» ä»£ç å¤ç”¨\n",
    "\n",
    "æ‰€æœ‰å‡½æ•°éƒ½å¯ä»¥ç‹¬ç«‹ä½¿ç”¨ï¼Œæ‚¨å¯ä»¥ï¼š\n",
    "- å•ç‹¬è°ƒç”¨æ•°æ®åŠ è½½å‡½æ•°å¤„ç†å…¶ä»–åŸºé‡‘\n",
    "- ä¿®æ”¹æƒé‡ç”Ÿæˆé€»è¾‘å®ç°ä¸åŒç­–ç•¥\n",
    "- è°ƒæ•´å†å¹³è¡¡é¢‘ç‡é€‚åº”ä¸åŒæŠ•èµ„é£æ ¼\n",
    "- å¢å¼ºå¯è§†åŒ–åŠŸèƒ½æ·»åŠ æ›´å¤šåˆ†æç»´åº¦\n",
    "\n",
    "**Happy Coding! ğŸ‰**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
